{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching jobs titles to resumes\n",
    "The challenges in this mini project:<br>\n",
    "1. The resumes and the jobs were in two different file types.\n",
    "2. They had to be loaded into the jupyter NB using different methods. \n",
    "3. Both were loaded into dictionaries\n",
    "4. They were converted to dataframes and cleaned.\n",
    "5. Words were vectorized and then compared using consine similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import docx2txt\n",
    "import pickle\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load job descriptions and resumes into pandas dictionary\n",
    "resume = {}\n",
    "for file in glob.glob(\"/Users/dahliashamir/Documents/GitHub/NLP_project/CVs/*.docx\"):\n",
    "    resume[file.split('.')[0]] = docx2txt.process(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_new = {}\n",
    "for key in resume:\n",
    "    key.replace(key, key.title())\n",
    "    new_key = key.lstrip('/Users/dahliashamir/Documents/GitHub/NLP_project/')\n",
    "    resume[new_key] = resume.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['-Designer-Resume-Sample-MSWord-Download', 'Business-Analyst-Resume-Example-MSWord-Download', 'Electrician-Resume-Sample-MSWord-Download', 'Accounting-Resume-Sample-MSWord-Download', '-Service-Representative-Resume-Sample-MSWord-Download', 'y-hotel-front-desk-resume-sample-MSWord-download', '-Analyst-Resume-Example-MSWord-Download', 'English-Tutor-Resume-Sample-MSWord-Download', 'Shipping-and-Receiving-Clerk-Resume-Sample-MSWord-Download', 'Experienced_Full-Stack_Developer', '-stylist-resume-sample-MSWord-Download', 'Music-Resume-Sample-MSWord-Download', 'School-Bus-Driver-Resume-Sample-MSWord-Download', 'keeping-Resume-Sample-MSWord-Download', '-janitor-resume-sample-MSWord-download', '-Labor-Resume-Sample-MSWord-Download', 'Sales-Associate-Resume-Sample-MSWord-Download (1)', 'Truck-Driver-Resume-Sample-MSWord-Download', 'Flight-Attendant-Resume-MSWord-Download', 'Bank-Teller-Resume-Sample-MSWord-Download', 'Bookkeeper-Resume-Sample-MSWord-Download', '-Driver-Resume-Sample-Download', 'very-Driver-Resume-Sample-MSWord-Download', 'Elementary-Teacher-Resume-Sample-MSWord-Download', 'Makeup-Artist-Resume-Sample-MSWord-Download', 'Retail-Manager-Resume-Sample-MSWord-Download', 'Software-Engineer-Resume-Sample-MSWord-Download', 'Maintenance-Worker-Resume-Sample-MSWord-Download', 'y-Resume-Sample-MSWord-Download', 'Sales-Associate-Resume-Sample-MSWord-Download', 'Warehouse-Worker-Resume-Sample-MSWord-Download', 'Acting-Resume-Sample-Download-MSWord'])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_names</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>designer resume sample msword download</td>\n",
       "      <td>graphic designer resume sample(xxx)-xxx-xxxx |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business analyst resume example msword download</td>\n",
       "      <td>business analyst resume sample(xxx)-xxx-xxxx |...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         doc_names  \\\n",
       "0           designer resume sample msword download   \n",
       "1  business analyst resume example msword download   \n",
       "\n",
       "                                               words  \n",
       "0  graphic designer resume sample(xxx)-xxx-xxxx |...  \n",
       "1  business analyst resume sample(xxx)-xxx-xxxx |...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean resume dictionary and prepare for resume dataframe\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def resume_dict_to_df(text):\n",
    "    # make lower case\n",
    "    low_case = {key: value.lower() for (key, value) in text.items()}\n",
    "    low_case_key = dict((k.lower(), v) for k, v in low_case.items()) \n",
    "    # remove underscore\n",
    "    no_underscore_resume = {key: value.replace('__', ' ') for (key, value) in low_case_key.items()}\n",
    "    # remove white spaces\n",
    "    no_wspace_resume = {key: value.replace(\"   \", \"\") for (key, value) in no_underscore_resume.items()}\n",
    "    # remove \\n from values\n",
    "    nresume = {key: value.replace(\"\\n\", \"\") for (key, value) in no_wspace_resume.items()}\n",
    "    #dashes_in_key\n",
    "    final_resume = {key.replace(\"-\", \" \"): value for (key, value) in nresume.items()}\n",
    "    resume_df = pd.DataFrame(final_resume, index=[0]).T\n",
    "    resume_df.reset_index(inplace = True)\n",
    "    resume_df.rename(columns = {'index':'doc_names', 0: 'words'}, inplace = True)\n",
    "    return resume_df\n",
    "\n",
    "resume_df = clean_resume_dict_text(resume)\n",
    "resume_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading pickle files to dictionary.\n",
    "directory = '/Users/dahliashamir/Documents/GitHub/NLP_project/positions'\n",
    "os.chdir(directory)\n",
    "# Create empty dictionary to save data\n",
    "pos_dict = {}\n",
    "\n",
    "# Loop over files and read pickles\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith('.pkl') :\n",
    "        with open(file, 'rb') as f:\n",
    "            pos_dict[file.split('.')[0]] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos_dict had many unnecessary detail. This was simplified to job_kw dictionary (one key and one value).\n",
    "job_kw = {}\n",
    "for v in pos_dict.values():\n",
    "    job_kw.update({v['title'] : v['basic_qualifications']})\n",
    "    \n",
    "#print(job_kw['Senior UX Designer, AWS Honeycode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert resume dict to resume df\n",
    "def postion_dict_to_df(job_kw):\n",
    "    positions_df = pd.DataFrame(job_kw, index=[0]).T\n",
    "    positions_df.reset_index(inplace = True)\n",
    "    #positions_df.columns\n",
    "    positions_df.rename(columns = {'index':'job_title', 0: 'job_description'}, inplace = True)\n",
    "    return positions_df\n",
    "\n",
    "positions_df = postion_dict_to_df(job_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean job descriptions and resumes by removing punctuation, stop words, and converting all text to lowercase.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if word.isalnum() or word.isspace()])\n",
    "    tokens = word_tokenize(text)\n",
    "    text = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(text)\n",
    "\n",
    "positions_df['clean_description'] = positions_df['job_description'].apply(lambda x: clean_text(x))\n",
    "resume_df['clean_resume'] = resume_df['words'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume 0 matches with job 'EE Lead CTA'\n",
      "Resume 1 matches with job 'Consumer Insights Manager, Payments Brand & Insights'\n",
      "Resume 2 matches with job 'Hardware Development Manager, AWS Server Engineering'\n",
      "Resume 3 matches with job 'Tax Manager, Prime Video, Digital Tax '\n",
      "Resume 4 matches with job 'Cloud Support Eng. I (DEP)'\n",
      "Resume 5 matches with job 'Partner Funding PM, AWS Partner Scalable GTM Migration & Funding Programs'\n",
      "Resume 6 matches with job 'Business Intel Engineer'\n",
      "Resume 7 matches with job 'Principal Research Scientist, Modeling and Optimization'\n",
      "Resume 8 matches with job 'Warehouse Specialist, Failure Analysis'\n",
      "Resume 9 matches with job 'Principal Solution Architect (SA), Application Modernization Lab, Application Modernization Lab'\n",
      "Resume 10 matches with job 'Principal Business Development Lead – Greenfield GTM Strategy'\n",
      "Resume 11 matches with job 'Global Latin Music Programmer, Music Industry'\n",
      "Resume 12 matches with job 'Amazon Fresh Overnight Grocery Associate - Woodland Hills, Ca'\n",
      "Resume 13 matches with job 'AWS Communications Leader '\n",
      "Resume 14 matches with job 'Data Center Construction Manager (New Zealand), Data Center Planning & Delivery'\n",
      "Resume 15 matches with job 'Data Center Construction Manager (New Zealand), Data Center Planning & Delivery'\n",
      "Resume 16 matches with job 'Principal Business Development Lead – Greenfield GTM Strategy'\n",
      "Resume 17 matches with job 'IT Support Associate II, OpsTechIT'\n",
      "Resume 18 matches with job 'Onsite Medical Representative, WHS'\n",
      "Resume 19 matches with job 'Cloud Support Eng. I (DEP)'\n",
      "Resume 20 matches with job 'Principal IT App Analyst- Management Financial, AWS Fintech'\n",
      "Resume 21 matches with job 'Carrier Manager'\n",
      "Resume 22 matches with job 'SDE II (Embedded Firmware) Amazon Glow, Amazon Glow'\n",
      "Resume 23 matches with job 'Principal Research Scientist, Modeling and Optimization'\n",
      "Resume 24 matches with job 'MGR, Quality Engineering Manager, Devices Lab126 Quality'\n",
      "Resume 25 matches with job 'Principal Business Development Lead – Greenfield GTM Strategy'\n",
      "Resume 26 matches with job 'Software Dev Eng – Test (L5), Amazon GuardDuty'\n",
      "Resume 27 matches with job 'Production Facilities Manager '\n",
      "Resume 28 matches with job 'Virtual Customer Care Advisor, Virtual Customer Care - Amazon Pharmacy'\n",
      "Resume 29 matches with job 'Principal Business Development Lead – Greenfield GTM Strategy'\n",
      "Resume 30 matches with job 'Warehouse Specialist, Failure Analysis'\n",
      "Resume 31 matches with job 'Sr.Ontologist'\n",
      "0     graphic designer resume samplexxxxxxxxxx youre...\n",
      "1     business analyst resume samplexxxxxxxxxx youre...\n",
      "2     electrician resume123 address city state zip c...\n",
      "3     accounting resume sample6254 south street new ...\n",
      "4     customer service resume 2498 rocky ridge dr ro...\n",
      "5     hospitality hotel front desk resume sample1400...\n",
      "6     data analyst resume samplexxxxxxxxxx youremail...\n",
      "7     english tutor resume sample1379 mulberry lane ...\n",
      "8     shipping receiving clerk resume123 address cit...\n",
      "9     experienced fullstack developerpython c sqlkir...\n",
      "10    hair stylist resume sample843 3542125 jessicaw...\n",
      "11    music resume samplemusicgmailcom 123 address t...\n",
      "12    school bus driver resume sample742 evergreen t...\n",
      "13    housekeeping resume sample3378 kelley avenue n...\n",
      "14    janitor resume combination242 santa monica blv...\n",
      "15    construction labor resume sample1010 south str...\n",
      "16    sales associate resumexxxxxxxxxx youremailcom ...\n",
      "17    truck driver resume sample1632 east street bos...\n",
      "18    flight attendant resume sample4155452187 youre...\n",
      "19    123 address city state zip codexxxxxxxxxx your...\n",
      "20    bookkeeper resume sample123 address city state...\n",
      "21    cdl driver resume samplexxx xxxxxxx youremailc...\n",
      "22    delivery driver resume sample242 santa monica ...\n",
      "23    elementary teacher sample resumexxxxxxxxxx you...\n",
      "24    makeup artist resume samplexxxxxxxxxx youremai...\n",
      "25    retail manager resume sample242 santa monica b...\n",
      "26    software engineer resume sample1632 east stree...\n",
      "27    maintenance worker resume sample1156 illustrio...\n",
      "28    nanny resume samplexxxxxxxxxx youremailcom 123...\n",
      "29    sales associate resumexxxxxxxxxx youremailcom ...\n",
      "30    warehouse worker resume sample1753 south lane ...\n",
      "31    acting resume sample298 west 44th street new y...\n",
      "Name: clean_resume, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Match job descriptions to resumes using cosine similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_jobs = tfidf_vectorizer.fit_transform(positions_df['clean_description'])\n",
    "tfidf_resumes = tfidf_vectorizer.transform(resume_df['clean_resume'])\n",
    "\n",
    "matches = []\n",
    "for i, resume in enumerate(tfidf_resumes):\n",
    "    similarities = cosine_similarity(resume, tfidf_jobs)[0]\n",
    "    job_index = similarities.argmax()\n",
    "    job_title = positions_df.iloc[job_index]['job_title']\n",
    "    matches.append({'resume_index': i, 'job_title': job_title})\n",
    "\n",
    "# Print the matches\n",
    "for match in matches:\n",
    "    print(f\"Resume {match['resume_index']} matches with job '{match['job_title']}'\")\n",
    "print(resume_df['clean_resume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
